<!DOCTYPE html>
<!--[if lt IE 7]>      <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]>         <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]>         <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>Sai Vemprala</title>
  <meta name="description" content="">
  <meta name="viewport" content="width=device-width">
  <link rel='shortcut icon' type='image/x-icon' href='favicon.ico' />
  <link rel="apple-touch-icon-precomposed" href="apple-touch-icon-precomposed.png">
  <link rel="apple-touch-icon-precomposed" href="apple-touch-icon-72x72-precomposed.png">
  <link rel="apple-touch-icon-precomposed" href="apple-touch-icon-114x114-precomposed.png">
  <link rel="apple-touch-icon-precomposed" href="apple-touch-icon-144x144-precomposed.png">

  <link rel="stylesheet" href="css/normalize.min.css">
  <link rel="stylesheet" href="css/main.css">
  <script src="https://use.fontawesome.com/9cf79ea55e.js"></script>
  <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.10.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="js/vendor/jquery-1.10.1.min.js"><\/script>')</script>
  <script src="js/vendor/jquery.hashchange.min.js"></script>
  <script src="js/vendor/jquery.easytabs.min.js"></script>
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-31757777-1', 'auto');
  ga('send', 'pageview');
  </script>

  <script src="js/main.js"></script>
  <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
      <script>window.html5 || document.write('<script src="js/vendor/html5shiv.js"><\/script>')</script>
      <![endif]-->
</head>
  <body class="bg-fixed bg-1">
<!--[if lt IE 7]>
    <p class="chromeframe">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> or <a href="http://www.google.com/chromeframe/?redirect=true">activate Google Chrome Frame</a> to improve your experience.</p>
    <![endif]-->
   <div class="main-container">
    <div class="main wrapper clearfix">
      <!-- Header Start -->
        <header id="header">
            <div id="logo">
                <h3>
                    SAI VEMPRALA
                </h3>
            </div>
        </header>
        <!-- Header End -->
        <!-- Main Tab Container -->
        <div id="tab-container" class="tab-container">
          <!-- Tab List -->
            <ul class='etabs'>
                <li class='tab' id="tab-about">
                  <a href="#about"><i class="fa fa-user"></i><span> About Me</span></a>
                </li>
                <li class='tab'>
                  <a href="#exp"><i class="fa fa-briefcase"></i><span> Experience </span></a>
                </li>
                <li class='tab'>
                  <a href="#projects"><i class="fa fa-code"></i><span> Projects </span></a>
                </li>
                <li class='tab'>
                  <a href="#pubs"><i class="fa fa-book"></i><span> Contributions </span></a>
                </li>
                <li class='tab'>
                    <a href="#achieve"><i class="fa fa-trophy"></i><span> Achievements </span></a>
                  </li>
                <li class='tab'>
                  <a href="#contact"><i class="fa fa-envelope"></i><span> Contact</span></a>
                </li>
            </ul>
          <!-- End Tab List -->
            <div id="tab-data-wrap">
              <!-- About Tab Data -->
                <div id="about">
                    <section class="clearfix">
                        <div class="g2">

                            <div class="info">
                                <h4>
                                    SAI HEMACHANDRA VEMPRALA
                                </h4>
                                <p align="justify">
                                    I am currently a researcher in the Autonomous Systems group at Microsoft. My areas of focus are aerial robotics, autonomous localization/planning, computer vision and machine learning. </p>
                                    <p align="justify">
                                    
                                    In 2019, I received my PhD from the Texas A&M University, where I was part of the <a href="https://unmanned.tamu.edu">Unmanned Systems Lab</a>, headed by <a href="https://engineering.tamu.edu/mechanical/people/saripalli">Dr. Srikanth Saripalli</a>. My PhD thesis was about collaborative localization and navigation for groups of vision based unmanned aerial vehicles. During my PhD years, I spent the summer of 2016 as a robotics intern in Millennium Engineering at the NASA Ames Research Center. At Millennium, I helped develop localization and autonomous navigation pipelines for a quadrotor UAV to navigate challenging subterranean, GPS-denied environments.
                                </p>
                                <p align="justify">
                                    Prior to my PhD, I received my Master of Science in Electrical Engineering from the Arizona State University in 2013. During these years, I was part of the Extreme Environment Robotics Lab (EERL) at ASU, headed by the late <a href="https://www-robotics.jpl.nasa.gov/people/Alberto_Behar/">Dr. Alberto Behar</a>. As part of the EERL team, I worked on developing software and lower-level firmware for the <a href="http://www.wissard.org/node/259">Micro Subglacial Lake Exploration Device</a> (MSLED), an underwater robot for exploring subglacial lakes in Antarctica that was deployed as part of the Whillans Ice Stream Subglacial Access Research Drilling (WISSARD) expedition. I was also the team lead for the <a href="https://dtm.carnegiescience.edu/research/projects/bento">BENTO</a> project,which involved developing hardware and software for a remote volcano monitoring system. I also worked as a Firmware Engineering intern at Intel Corporation in 2013: where I developed embedded firmware for the Intel BioSport headset.
                                </p>
                                <p align="justify">
                                    My undergraduate degree was in Electrical and Electronics Engineering from the JNTU Hyderabad, India, from which I graduated in 2011. During my undergraduate program, I worked on developing algorithms for computational analysis of electrical distribution systems. &nbsp;
                                    </p>

                                </p>
                            </div>

                        </div>
                        <div class="g1">
                            <div class="main-links sidebar">
                                <ul>
                                    <li>   <img src="images/me2.png" width="270" height="300"> </li>
                                    <li>
                                        <p align="center">
                                        <a target="_blank" href="SaiHVemprala_CV.pdf"> Download CV (PDF)</a>
                                    </p>
                                    </li>
                                </ul>



                            </div>
                        </div>
                        <div class="break"></div>

                    </section><!-- content -->
                </div>
              <!-- End About Tab Data -->
              <!-- Resume Tab Data -->
                <div id="exp">
                    <section class="clearfix">
                        <div class="g3">
                            <h4>
                                Research and Work Experience
                            </h4>
                            <ul class="no-list work">
                                    <li>
                                            <h6>
                                                Researcher : Microsoft Corporation <br/><span align="right" class="label label-warning">July 2019 - <emph>present</emph></span>
                                                
                                            </h6>
                                            <p align="justify">
                                                - Researcher in the Autonomous Systems group of the AI & Research division.
                                            </p>
                                            
                                        </li>
                              <li>
                                  <h6>
                                      Research Assistant : Unmanned Systems Lab, Texas A&M University <br/><span align="right" class="label label-info">Jan 2017 - May 2019</span>
                                      
                                  </h6>
                                  <p align="justify">
                                      - Primary PhD research: Collaborative localization and navigation for micro aerial vehicle swarms using vision. <br>
                                      - Developing a computer vision based cancer tumor tracking system in collaboration with Mayo Clinic Arizona. <br>
                                      - Winner of the 2018 TAMU Data Science contest: developed predictive models for taxi revenue using existing public domain data from the city of Chicago. 
                                  </p>
                              </li>
                                <li>
                                    <h6>
                                        Research Assistant : Autonomous Systems Laboratory, ASU <br/><span align="right" class="label label-info">Jan 2013 - Dec 2016</span>
                                        
                                    </h6>
                                    <p align="justify">
                                        - Primary research focused on autonomous navigation of unmanned vehicles, GPS denied localization and planning for micro aerial vehicles. <br>
                                        - Developed a 'natural motion' framework for a humanoid robot named Baxter. <br>
                                        - Gained hands-on experience in sensor fusion, ROS based middleware development, embedded systems, various commercial UAV platforms.
                                    </p>
                                </li>
                                <li>
                                    <h6>
                                        Graduate Intern : Millennium Engineering and Integration <br/><span align="right" class="label label-info">May 2016 - Aug 2016 </span>
                                        
                                    </h6>
                                    <p align="justify">

                                        - Developed the software architecture for sensing and communication for a quadrotor UAV and developed a framework for estimation and navigation in subterranean GPS denied environments. <br> 
                                        - Worked on developing a 6DOF Simulink model for simulation of a fixed wing UAV. <br> 
                                        - Implemented attitude stabilization on open source autopilot hardware for an experimental unmanned aircraft.
                                        - Developed image processing software for analyzing multispectral satellite images.
                                    </p>
                                </li>
                                <li>
                                    <h6>
                                        Research Aide : Extreme Environment Robotics Laboratory, ASU <br/><span align="right" class="label label-info">May 2012 - Dec 2013</span>                                     
                                    </h6>

                                    <p align="justify">
                                        - Developed a .NET based ground station software and low-level firmware for an underwater robot (MSLED). <br>
                                        - Designed sensor fusion pipelines for gas, weather and seismic sensors, developed embedded firmware and data transmission protocols for sensing and reporting volcanic and seismic activity through satellite communication.
                                    </p>
                                </li>
                                <li>
                                    <h6>
                                        Graduate Intern : Intel Corporation <br/><span align="right" class="label label-info">Jun 2013 - Aug 2013</span>
                                        
                                    </h6>

                                    <p align="justify">
                                        - Designed embedded firmware for the biometric headset BioSport. <br>
                                        - Involved in hardware design, sensor fusion and signal processing algorithms for Biosport.
                                    </p>
                                </li>
                            </ul>
                            <h4>
                                Education
                            </h4>
                            <ul class="no-list work">
                                <li>
                                    <h6>
                                        Texas A&M University (previously at Arizona State University) USA <br/><span align="right" class="label label-success">2014 - 2019</span>
                                        Doctor of Philosophy
                                    </h6>
                                    <p>
                                        PhD in Mechanical Engineering
                                    </p>
                                </li>
                                <li>
                                    <h6>
                                        Arizona State University, USA <br/><span align="right" class="label label-success">2012 - 2013</span>
                                        Master of Science
                                    </h6>
                                    <p>
                                        MS in Electrical Engineering
                                    </p>
                                </li>
                                <li>
                                    <h6>
                                        Guru Nanak Engineering College, India <br/>
                                        <span align="right" class="label label-success">2007 - 2011</span>
                                        Bachelor of Technology
                                    </h6>
                                    <p>
                                        B.Tech. in Electrical and Electronics Engineering
                                    </p>
                                </li>
                            </ul>
                        </div>

                    </section>
                </div>
              <!-- End Resume Tab Data -->
              <!-- Portfolio Tab Data -->
                <div id="projects">
                    <section class="clearfix">
                        <div class="g4">
                           <h4> Uncertainty-aware Planning for Micro Aerial Vehicle Swarms</h4>
                            <div style="float: right;">
                                <img style="vertical-align:middle" src="images/coplan.png" width="300" height="140" style="margin: 15px 0px">
                            </div>
                            <p>
                                In this project that forms the second part of my PhD thesis, I investigated the idea of collaborative uncertainty-aware path planning for vision based micro aerial vehicles. For vehicles that are equipped with cameras and can localize collaboratively (see below), a heuristic based approach attempts to capture the estimated "quality" of localization from various viewpoints. Evolutionary algorithms were integrated with an RRT based path planning framework to result in plans which allow the vehicles to navigate intelligently towards areas that can improve their vision based localization accuracy: such as moving only in well-lit locations, observing texture-rich objects, building denser maps before navigating etc.
                            </p>
                        </div>

                        <hr>
                        <div class="g4">
                           <h4> Collaborative Localization for Micro Aerial Vehicle Swarms</h4>
                            <div style="float: right;">
                                <img style="vertical-align:middle" src="images/cl.png" width="300" height="150" style="margin: 15px 0px">
                            </div>
                            <p>
                                As the first part of my PhD thesis, I developed a collaborative localization pipeline that is applicable for a swarm of multirotor aerial vehicles with each vehicle using a monocular camera as its primary sensor. Images are captured continuously from each vehicle and Feature detection and matching are performed between the individual views, thus allowing for reconstruction of the surrounding environment. This sparse reconstruction is then used by the vehicles for individual localization in a decentralized fashion. The vehicles are also capable of computing relative poses between each other and fusing them with individual pose estimation occasionally for enhanced accuracy. Even when cross-correlations between vehicles are not tracked, covariance intersection allows for robust pose estimation between vehicles.
                            </p>
                        </div>

                        <hr>
                        <div class="g4">
                            <h4> Real Time Cancer Tumor Tracking for Proton Beam Therapy </h4>
                            <div style="float: right;">
                                <img style="vertical-align:middle" src="images/rtt.png" width="300" height="150" style="margin: 15px 0px">
                            </div>
                            <p>
                                In collaboration with Mayo Clinic Arizona, I developed a real-time computer vision based tracking system for markers implanted in cancer tumors. The target application is to control a state-of-the-art proton beam targeting system according to tumor motion which is caused by the breathing cycles of the patient and other kinds of natural organ motion. It is common practice to embed tiny fiducial markers in the tumors in order to be visible in the X-ray spectrum. Computer vision techniques such as normalized cross correlation, image saliency maps etc. are utilized in conjunction with kernelized cross-correlation filters to track these tiny markers during X-ray fluoroscopy. The tracking method is able to handle high amounts of noise and various types of markers in order to achieve accurate and real time tracking.
                            </p>
                        </div>

                        <hr>
                        <div class="g4">
                            <h4> Drone Detection through Depth Images </h4>
                            <div style="float: right;">
                                <img style="vertical-align:middle" src="images/drdet.png" width="300" height="150" style="margin: 15px 0px">
                            </div>
                            <p>
                                In collaboration with researchers from Universidad Politecnica de Madrid and MIT's ACL lab, I am working on a framework for detecting and localizing multirotor UAVs using depth images. A specific advantage of depth sensing versus other detection methods is that a depth map is able to provide 3D relative localization of the objects of interest, making it easier to develop strategies such as collision avoidance. In our work, a dataset of synthetic depth maps of drones has been first generated in the Microsoft AirSim UAV simulator and used to train a state-of-the-art deep learning-based drone detection model. The proposed detection technique, while trained only on simulation, has been validated in several real-life depth map sequences. It also generalizes well to multiple types of drones flying at up to 2 m/s, achieving an average precision of 98.7%, an average recall of 74.7% and a record detection range of 9.5 meters.
                            </p>
                        </div>

                        <hr>
                        <div class="g4">
                            <h4> Ars Robotica: Robots in Theater </h4>
                            <div style="float: right;">
                                <img style="vertical-align:middle" src="images/ar.png" width="300" height="150" style="margin: 15px 0px">
                            </div>
                            <p>
                                Ars Robotica was a collaboration between artists, theater performers and roboticists: to understand the fluidity and expressiveness of human movement and the possibility of its reproduction by robotic platforms. Using the Rethink Robotics Baxter as a test platform, we worked on defining and achieving human-like movement on the robot. We obtained movement data from expert human performers through various sensors: all the way from a Microsoft Kinect to a 12 camera high-precision, Optitrack system; which we then used as training data to construct "primitives", thus forming a vocabulary for motion. We later managed to express complex movements as a temporal combination of such primitives: thus helping create a framework for autonomous interpretation and expression of human-like motion through Baxter.
                            </p>
                        </div>
                        <hr>

                        <div class="g4">
                            <h4> Micro Subglacial Lake Exploration Device </h4>
                            <div style="float: right;">
                                <img style="vertical-align:middle" src="images/ms.png" width="300" height="150" style="margin: 15px 0px">
                            </div>
                            <p>
                                As part of a team at the Extreme Environment Robotics Laboratory, I worked on the development of onboard firmware (Arduino) and ground station software (C#/.NET) for a subglacial lake and aquatic exploration robot called MSLED. MSLED consists of a submersible mothership/explorer combination, and uses MEMS sensor and imaging technologies to investigate deep, remote and chemically challenging aquatic environments. Its sensory payload consists of a camera, inertial measurement unit, CTD sensor, data from which is transferred to the surface through a fiber optic cable. MSLED was deployed successfully twice in Lake McMurdo, Antarctica as part of the WISSARD program, while WISSARD played a crucial role in the <a href="https://www.nsf.gov/news/news_summ.jsp?cntn_id=132267">discovery of subglacial life under the Antarctic ice</a>.
                            </p>
                        </div>
                        <hr>

                        <div class="g4">
                            <h4> BENTO Volcano Monitor </h4>
                            <div style="float: right;">
                                <img style="vertical-align:middle" src="images/bb.png" width="300" height="150" style="margin: 15px 0px">
                            </div>
                            <p>
                                I led a team of graduate students on a project involving hardware and software design of expendable "volcanic monitor" capsules which monitor and transmit data about rapidly evolving volcanic conditions. The monitors are equipped with a number of sensors (seismic, gas, temperature etc.) and use a minimal data packaging and transmission protocol using the Iridium satellite modems that allows for real time compilation and dissemination of scientific data. Volcano monitors were deployed in Nicaragua, Italy, Iceland and Greenland.

                            </p>
                        </div>
                    </section>
                </div>

                <div id="pubs">

                <h4 id="papers">Journal Papers</h4>
                <ul>
                   <li> Sai Vemprala, Srikanth Saripalli, "Collaborative Localization for Micro Aerial Vehicles", <em>under review.</em> </li>
                   <li> Adrian Carrio, Jesus Tordesillas Torres, Sai Vemprala, Srikanth Saripalli, Pascual Campoy, "Onboard detection and localization of drones using depth maps", <em>IEEE Access, pending publication.</em>
                   <li>Alberto E. Behar, Daming D. Chen, [et al. including Sai H. Vemprala].  <a target="_blank" href="docs/msled.pdf"><strong>MSLED: The Micro Subglacial Lake Exploration Device</strong></a>. <em>Underwater Technology, 33.1, 2015.</em></li>                        
                </ul>
                <h4 id="papers">Conference Papers</h4>
  <ul>
      <li>Sai Vemprala, Srikanth Saripalli, Carlos Vargas, Martin Bues, Yanle Hu, Jiajian Shen. <a target="_blank" href="docs/mayo.pdf"><strong> "Real-time Tumor Tracking for Pencil Beam Scanning Proton Therapy"</strong></a>, <em> 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2018), Madrid, Spain, 2018, pp. 4434-4440.</em></li>
      <li>Adrian Carrio, Sai Vemprala, Andres Ripoll, Srikanth Saripalli, Pascual Campoy. <a target="_blank" href="https://arxiv.org/abs/1808.00259"><strong> "Drone Detection using Depth Maps"</strong></a>, <em>2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2018), Madrid, Spain, 2018, pp. 1034-1037.</em></li>
      <li>Sai Vemprala, Srikanth Saripalli. <a target="_blank" href="https://arxiv.org/abs/1804.02510"><strong>"Monocular Vision based Collaborative Localization for Micro Aerial Vehicle Swarms"</strong></a>, <em>18th IEEE International Conference on Unmanned Aerial Systems (ICUAS 2018), Dallas, USA, 2018, pp. 315-323.</em></li>
      <li>Sai Vemprala, Srikanth Saripalli. <strong>"Uncertainty-aware Planning for Vision Based Multirotor Swarms"</strong>, <em>Proceedings of the AHS International 74th Annual Forum, Phoenix, USA, 2017, pp.
        1774-1783.</em></li>
      <li>Sai Vemprala, Srikanth Saripalli. <a target="_blank" href="docs/icra18.pdf"><strong>"Vision based Collaborative Path Planning for Micro Aerial Vehicles"</strong></a>, <em>2018 IEEE International Conference on Robotics and Automation (ICRA), Brisbane, Australia, 2018, pp. 1-7.</em></li>
      <li>Sai Vemprala, Srikanth Saripalli. <a target="_blank" href="docs/swarms.pdf"><strong>"Vision Based Collaborative Localization for Swarms of Aerial Vehicles"</strong></a>. <em>Proceedings of the AHS International 73rd Annual Forum, Dallas, USA, 2017, pp. 2980-2985.</em></li>
      <li>Sai Vemprala, Srikanth Saripalli. <a target="_blank" href="docs/iros16.pdf"><strong>"Vision Based Collaborative Localization of Multirotor Vehicles"</strong></a>. <em>2016
        IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Daejeon, South Korea, 2016, pp. 1653-1658.</em></li>  
      <li> Ravi Babu P., Kumar M.P.V.V.R., Hemachandra V.S., Vanamali M.P.R. <strong>"A Novel Power Flow Solution Methodology for Large Radial Distribution Systems"</strong></a>. <em>IEEE International Conference on Computational Technologies SIBIRCON 2010.</em> </li>
      <li> Ravi Babu P., Vanamali M.P.R., Kumar M.P.V.V.R., Hemachandra V.S. <strong>"Distribution System Network Reconfiguration using L-E Method"</strong></a>. <em>Annual IEEE India Conference 2010.</em> </li>
  </ul>

  <h4 id="posters">Posters</h4>
  <ul>
    <li>Sai Vemprala, Ian Shelanskey, Matthew Ragan, Lance Gharavi, Srikanth Saripalli. <a target="_blank" href="docs/baxter.pdf">Ars Robotica: A Movement Framework for Robots in Theater</a>. <em>Workshop on Artistically Skilled Robots</em>. Daejeon, Korea, 2016.</li>
    <li>Sai Vemprala, Srikanth Saripalli. Autonomous Exploration using UAVs. <em>AAAI Conference on Artificial Intelligence 2016</em>. Phoenix, AZ, February 2016.</li>
  </ul>

  <h4 id="posters">Patents</h4>
  <ul>
    <li><strong>System and method for data transmission and power supply capability over an audio jack for mobile devices</strong>; Indira Negi, Lakshman Krishnamurthy, Brian K. Vogel, Darren S. Crews, Sai H. Vemprala, Xiaochao Yang, Howard D. Millett, Alexander Essaian, Alanson P. Sample: US Patent 10,165,355 (issued 12/25/2018) </li>  
    <li><strong>System and method for device action and configuration based on user context detection from sensors in peripheral devices </strong>; Indira Negi, Lakshman Krishnamurthy, Fuad Al-Amin, Xiaochao Yang, Brian K. Vogel, Jun Li, Alexander Essaian, Sai H. Vemprala, Donnie H. Kim, Lama Nachman, Haibin Liu: US Patent 10,117,005 (issued 10/30/2018) </li>
  </ul>

  <h4 id="others">Other presentations</h4>
  <ul>
    <li>Sai Vemprala. <strong>Sampling based Path Planning for Unmanned Aerial Vehicles</strong>. <em>IROS 2017 Workshop on Complex Collaborative Systems. </em>Vancouver, Canada, 2017.</li>
    <li>Sai Vemprala, Srikanth Saripalli. <strong>Vision based MAV Swarms in a Photorealistic Simulation Framework. </strong> <em>1st International Symposium on Aerial Robotics.</em> Philadelphia, USA, 2017. </li>
    <li>Andres Mora, Sai Vemprala, Adrian Carrio, Srikanth Saripalli. <strong>Flight performance assessment of land
        surveying trajectories for multiple UAV platforms</strong></a>. <em>Workshop on Research, Education and Development of Unmanned Aerial Systems, RED-UAS 2015.</em> Cancun, Mexico, 2015.</li>
    <li>Lance Gharavi, Srikanth Saripalli, Sai Vemprala, Matthew Ragan, Ian Shelanskey. <strong>Ars Robotica</strong>. <em>Exemplar project at the a2ru National Conference</em> Virginia, USA, 2015.</li>
    <li>Sai Vemprala, Srikanth Saripalli. <strong>Autonomous exploration and navigation strategies for MAVs</strong></a>. <em>AHS International Specialists' Meeting on Unmanned Rotorcraft System 2015</em></li>
    <li>Alberto Behar, Sai Vemprala. <strong>BENTO: Volcanic monitoring</strong>. <em>Deep Carbon Observatory Sandpit Workshop on Gas Instrumentation.</em> Sicily, Italy, 2013.</li>
  </ul>

                </div>
                <div id="achieve">
                    <section class="clearfix">
                        <div class="g4">
                            
                                <h5> TAMUHack 2019: Best IoT hack winner</h5>
                            
                                <p>
                                    In 2019, I was part of the team that won the 'Best IoT Hack' category in the annual TAMUHack hackathon. Over 24 hours, we designed a system that performs facial recognition (while making sure it is a real person and not a picture by detecting eye blinks) along with voice verification for password-less authentication. We made use of Microsoft Azure's Cognitive Services API, thus allowing the system to run on low-power hardware. We deployed this system on a Qualcomm Dragonboard SBC.
                                </p>
                                <h5> TAMU Data Science contest: 1st place</h5>
                            
                                <p>
                                    In 2018, I won the Texas A&M University's Data Science contest. As part of the contest, I developed predictive models for estimating taxi revenue over time and location using public taxi ride data from the city of Chicago. I implemented ARIMA based forecasting as well as a LSTM-based recurrent neural network to generate accurate predictions, while comparing them with results from packages such as Facebook Prophet.
                                </p>
                           <h5> DAC 2018 System Design Contest: Top 5 finish</h5>
                            
                            <p>
                                In 2018, I led a team of graduate students that participated in the 2018 DAC System Design contest. The objective of the contest was to design a machine learning pipeline that can classify and detect objects in a multi-class custom dataset. The primary requirement was that the pipeline needs to run at a speed of >20 FPS on an NVIDIA Jetson TX2, while maximizing intersection-over-union (IoU) and minimizing power consumption. We constructed an object detection/classification pipeline using the Tiny YOLO v2 model, which was implemented on the TX2, along with several Jetson-specific optimizations in order to achieve 21 FPS of detection speed and over 80% IoU in validation. Evaluated over all these metrics, our team achieved a top 5 finish in the contest out of 61 teams worldwide. 
                            </p>
                        </div>

                </div>


              <!-- End Portfolio Data -->
              <!-- Contact Tab Data -->
                <div id="contact">
                    <section class="clearfix">
                       <div class="g1">
                         <div class="sny-icon-box">
                           <div class="sny-icon">
                              <i class="fa fa-globe"></i>
                            </div>
                            <div class="sny-icon-content">
                              <h4>Office Address</h4>
                              <p>ENPH Rm 421, 180 Spence St, College Station, TX - 77840</p>
                            </div>
                         </div>
                       </div>

                       <div class="g1">
                         <div class="sny-icon-box">
                             <a target="_blank" href="https://www.linkedin.com/in/saihv">
                           <div class="sny-icon">
                              <i class="fa fa-linkedin-square"></i>
                            </div>
                             </a>
                            <div class="sny-icon-content">
                              <h4>

                                    Connect on LinkedIn

                              </h4>

                            </div>
                         </div>
                       </div>

                       <div class="g1">
                        <div class="sny-icon-box">
                            <a target="_blank" href="https://www.github.com/saihv">
                          <div class="sny-icon">
                             <i class="fa fa-github"></i>
                           </div>
                            </a>
                           <div class="sny-icon-content">
                             <h4>
                                   GitHub
                             </h4>
                           </div>
                        </div>
                      </div>



                        <div class="g1">
                         <div class="sny-icon-box">

                            <div class="sny-icon">
                              <i class="fa fa-envelope"></i>
                            </div>
                            <div class="sny-icon-content">
                              <h4>

                                    Email

                              </h4>

                            svemprala (at) tamu [dot] edu

                            </div>
                         </div>
                       </div>
                       <div class="break"></div>

                    </section>
                </div>
              <!-- End Contact Data -->
            </div>
        </div>
        <!-- End Tab Container -->
        <footer>
            <p>
                Copyright (C) Sai Vemprala <script type="text/javascript">
  document.write(new Date().getFullYear());
</script>
            </p>
        </footer>
    </div><!-- #main -->

</div><!-- #main-container -->



</body>
</html>
